{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dcgan_for_mnist.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOjMxAS7q7tkkxJ5F9fHuB1"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"hWFkFHjnIe_D"},"source":["import time \n","import tqdm\n","import torch\n","import torch.nn as nn  \n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.animation as animation\n","\n","from torchvision import transforms\n","from torch.utils.data import DataLoader\n","from torchvision.datasets import MNIST\n","from torchvision.utils import make_grid\n","\n","from IPython.display import HTML\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PPVurLOvkLai"},"source":["# Using GPU\n","Before executing the cell, go to Runtime -> Change Runtime Type -> GPU"]},{"cell_type":"code","metadata":{"id":"KnSOSHzYKWZB"},"source":["X = torch.randn(3, 2)\n","print(X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lU2SvuN-NdXD"},"source":["X.device"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TWk_20lAknAx"},"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NcNkwbSSkzQ5"},"source":["X = torch.randn(3, 2)\n","print(X.device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oqYWbrjglYou"},"source":["# Prepare MNIST dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KJ5eDktoc2ge","executionInfo":{"status":"ok","timestamp":1616295508058,"user_tz":-480,"elapsed":22783,"user":{"displayName":"Yi Xuan Chan","photoUrl":"","userId":"11320233012469812964"}},"outputId":"adbadc24-b984-4d7c-8afe-f35d7d5e6119"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lfeGqd8udHB9"},"source":["path = '/content/gdrive/MyDrive/' # path to save MNIST dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m_xzRwUypzdf"},"source":["transform = transforms.Compose([\n","                                transforms.ToTensor(),\n","                                transforms.Normalize((0.5,), (0.5,))\n","])\n","dataset = MNIST(path, train=True, download=True,\n","                transform = transform)           \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h_NABQdZqNbJ"},"source":["len(dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wWah1kVBuV9s"},"source":["# Show a random image\n","idx = np.random.choice(len(dataset))\n","img, label = dataset[idx]\n","print('Image size: {}'.format(img.shape))\n","print('Label: {}'.format(label))\n","plt.axis('off')\n","plt.imshow(img.permute(1, 2, 0).squeeze(), cmap='gray')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aVVKyIglP0Tx"},"source":["def show_images(image_tensor, num_images=25, nrow=5, save=False): \n","  image_tensor = image_tensor.detach().to('cpu') \n","  image_tensor = (image_tensor + 1)/2  \n","  img = make_grid(image_tensor[:num_images], nrow=nrow).permute(1,2,0).squeeze()  \n","  if save:\n","    return img\n","  plt.axis('off')\n","  plt.imshow(img)\n","  plt.show()\n","  if save:\n","    return img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0p1JfgMQ5Ng7"},"source":["# create a dataloader\n","batch_size = 128\n","dataloader = DataLoader(dataset, batch_size=128, shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6OXovjSXk-Rd"},"source":["for i, data in enumerate(dataloader):\n","  X, _ = data  \n","  break\n","\n","show_images(X, 100, 10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X-5X8Wkoog_o"},"source":["# Input noise vector"]},{"cell_type":"code","metadata":{"id":"1iFRpp48ojgo"},"source":["def noise_vector(num, dim):\n","  # return a noise vector with width=height=1, channel=dim\n","  return torch.randn(num, dim, 1, 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"roIkeHqso5XA"},"source":["z = noise_vector(10, 100)\n","print(z.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qVcpMWROe9Ad"},"source":["# Generator Model"]},{"cell_type":"markdown","metadata":{"id":"lWQn7lEgpF6c"},"source":["**Each layer of generator:**\n","\n","\n","*   Transposed convolution for upsampling\n","*   Use batchnorm except for the last layer\n","*   Apply ReLU activation for all layers except for the output, which uses TanH\n","\n","Remember that the output size of transposed convolution is:\n","$$output size = (input size -1)*stride - 2*padding + kernel size$$\n","\n","Useful functions in building generator:\n","\n","\n","*   [ConvTranspose2d](https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html)\n","*   [BatchNorm2d](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html?highlight=batchnorm#torch.nn.BatchNorm2d)\n","*   [ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html?highlight=relu#torch.nn.ReLU)\n","*   [Tanh](https://pytorch.org/docs/stable/generated/torch.nn.Tanh.html?highlight=tanh#torch.nn.Tanh)\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"N_5UqL9CfCFz"},"source":["class Generator(nn.Module):\n","  '''\n","  z_dim: the length of the input noise vector, a scalar\n","  hidden_dim: size of the feature maps that are propagated through the generator, a scalar\n","  out_channel: number of channels in the output image, set to 1 for MNIST (black and white)\n","  '''\n","  def __init__(self, zdim, hidden_dim=64, out_channel=1):\n","    super(Generator, self).__init__()\n","    self.model = nn.Sequential(\n","        # layer 1, input is z (noise)\n","        nn.ConvTranspose2d(zdim, hidden_dim*4, kernel_size=4),\n","        nn.BatchNorm2d(hidden_dim*4),\n","        nn.ReLU(),\n","        # size (hidden_dim*4) x 4 x 4\n","\n","        # layer 2\n","        nn.ConvTranspose2d(hidden_dim*4, hidden_dim*2, kernel_size=4, stride=2, padding=1),\n","        nn.BatchNorm2d(hidden_dim*2),\n","        nn.ReLU(),\n","        # size (hidden_dim*2) x 8 x 8\n","\n","        # layer 3\n","        nn.ConvTranspose2d(hidden_dim*2, hidden_dim, kernel_size=4, stride=2, padding=2),   \n","        nn.BatchNorm2d(hidden_dim),\n","        nn.ReLU(),           \n","        # size (hidden_dim) x 14 x 14\n","\n","        # layer 4 (last layer)\n","        nn.ConvTranspose2d(hidden_dim, out_channel, kernel_size=4, stride=2, padding=1),\n","        nn.Tanh()\n","        # output size out_channel x 28 x 28\n","    )\n","\n","  def forward(self, X):\n","    return self.model(X)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M9_fuDIfSi3E"},"source":["From the DCGAN paper, the author suggested to initialize all weights from a zero-centered Normal distribution with standard deviation 0.02."]},{"cell_type":"code","metadata":{"id":"gDK6COU9SE2D"},"source":["# apply to Generator and Discriminator network\n","def init_weights(m):\n","  if type(m) == nn.Conv2d or type(m) == nn.ConvTranspose2d:\n","    nn.init.normal_(m.weight, mean=0.0, std=0.02)\n","  elif type(m) == nn.BatchNorm2d:\n","    nn.init.normal_(m.weight, mean=0.0, std=0.02)\n","    nn.init.constant_(m.bias, val=0.0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlnjhzDrfBWk"},"source":["gen = Generator(100)\n","gen.apply(init_weights)\n","print(gen)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z9wEKG3OPBA7"},"source":["z = noise_vector(1, 100)\n","fake = gen(z).detach()\n","print(fake[0].shape)\n","\n","plt.axis('off')\n","plt.imshow(fake[0].permute(1, 2, 0).squeeze(), cmap='gray')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OBsDIxZvfGC1"},"source":["# Discriminator Model"]},{"cell_type":"markdown","metadata":{"id":"k7ab8yAIUZ5D"},"source":["**Each layer of discriminator:**\n","\n","\n","*   Convolution for downsampling\n","*   Use batchnorm except for the last layer\n","*   Apply LeakyReLU activation with slope of 0.2 for all layers \n","\n","Remember that the output size of convolution is:\n","$$output size = (inputsize + 2*padding - kernelsize)/stride + 1$$\n","\n","Useful functions in building discriminator:\n","\n","\n","*   [Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html?highlight=conv2d#torch.nn.Conv2d)\n","*   [BatchNorm2d](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html?highlight=batchnorm#torch.nn.BatchNorm2d)\n","*   [LeakyReLU](https://pytorch.org/docs/stable/generated/torch.nn.LeakyReLU.html?highlight=leaky%20relu#torch.nn.LeakyReLU)\n","*   [Sigmoid](https://pytorch.org/docs/stable/nn.functional.html?highlight=sigmoid#torch.nn.functional.sigmoid)\n"]},{"cell_type":"code","metadata":{"id":"iPjEIzs7fHyI"},"source":["class Discriminator(nn.Module):\n","  '''\n","  im_channel: number of channels in the input image. Default is 1 for MNIST dataset\n","  hideen_dim: size of the feature maps that are propagated through the discriminator, a scalar\n","  '''\n","  def __init__(self, im_channel=1, hidden_dim=64):\n","    super(Discriminator, self).__init__()\n","    self.model = nn.Sequential(\n","        # layer 1, input is image of size im_channel x 28 x 28\n","        nn.Conv2d(im_channel, hidden_dim, kernel_size=4, stride=2, padding=1),\n","        nn.BatchNorm2d(hidden_dim),\n","        nn.LeakyReLU(0.02),\n","        # size (hidden_dim) x 14 x 14\n","\n","        # layer 2\n","        nn.Conv2d(hidden_dim, hidden_dim*2, kernel_size=4, stride=2, padding=2),\n","        nn.BatchNorm2d(hidden_dim*2),\n","        nn.LeakyReLU(0.02),\n","        # size (hidden_dim*2) x 8 x 8\n","\n","        # layer 3\n","        nn.Conv2d(hidden_dim*2, hidden_dim*4, kernel_size=4, stride=2, padding=1),\n","        nn.BatchNorm2d(hidden_dim*4),\n","        nn.LeakyReLU(0.02),\n","        # size (hidden_dim*4) x 4 x 4\n","\n","        # layer 4 (last layer)\n","        nn.Conv2d(hidden_dim*4, 1, kernel_size=4),\n","        nn.Sigmoid()\n","    )\n","  \n","  def forward(self, image):\n","    out = self.model(image)\n","    return out.view(len(image), -1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xSM7oQjRbvHb"},"source":["disc = Discriminator()\n","disc.apply(init_weights)\n","print(disc)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OvVfno2cfI6P"},"source":["# Start Training"]},{"cell_type":"code","metadata":{"id":"BDfnn7CyfLYo"},"source":["z_dim = 100\n","learning_rate = 0.0002\n","beta1 = 0.5\n","beta2 = 0.999\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# loss function\n","criterion = nn.BCELoss()\n","\n","# initialize generator, discriminator, optimizer\n","# optimizers for both Generator and Discriminator\n","gen = Generator(z_dim).to(device)\n","disc = Discriminator().to(device)\n","\n","\n","gen.apply(init_weights)\n","disc.apply(init_weights)\n","\n","optimG = torch.optim.Adam(gen.parameters(), lr=learning_rate, betas=(beta1, beta2))\n","optimD = torch.optim.Adam(disc.parameters(), lr=learning_rate, betas=(beta1, beta2))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b4B_Rp2ciXqp"},"source":["# fixed noise for visualization purpose\n","fixed_noise = noise_vector(100, z_dim).to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q7hXgCW0iyI8"},"source":["num_epochs = 20\n","\n","img_list = []\n","gen_losses = []\n","disc_losses = []\n","\n","iter = 0\n","\n","start_time = time.time()\n","for epoch in range(num_epochs):\n","  for i, data in enumerate(dataloader):\n","    real = data[0].to(device)\n","\n","    # update discriminator\n","    optimD.zero_grad()\n","    noise = noise_vector(len(real), 100).to(device)\n","    fake = gen(noise).detach()\n","    disc_fake_pred = disc(fake)\n","    disc_fake_loss = criterion(disc_fake_pred, torch.zeros_like(disc_fake_pred))\n","    disc_real_pred = disc(real)\n","    disc_real_pred = disc(real)\n","    disc_real_loss = criterion(disc_real_pred, torch.ones_like(disc_real_pred))\n","    disc_loss = (disc_fake_loss + disc_real_loss)/2\n","\n","    # record discrimator loss for later visualization purpose\n","    disc_losses.append(disc_loss.item())\n","    # calculate gradients of discriminator\n","    disc_loss.backward()\n","    # update optimizer\n","    optimD.step()\n","    \n","    # update generator\n","    optimG.zero_grad()\n","    noise2 = noise_vector(len(real), 100).to(device)\n","    fake2 = gen(noise2)\n","    disc_fake_pred2 = disc(fake2)\n","    gen_loss = criterion(disc_fake_pred2, torch.ones_like(disc_fake_pred2))\n","\n","    # record generator loss for later visualization purpose\n","    gen_losses.append(gen_loss.item())\n","    # calculate gradients of generator\n","    gen_loss.backward()\n","    # updatde optimizer\n","    optimG.step()\n","       \n","    if iter % 500 == 0 or ((epoch == num_epochs-1) and (i == len(dataloader) - 1)):\n","      with torch.no_grad():\n","        fixed_fake = gen(fixed_noise)\n","        img = show_images(fixed_fake, len(fixed_fake), nrow=10, save=True)        \n","        img_list.append(img)\n","    iter+=1\n","  # training status\n","  print('[{}/{}]\\tLoss_D: {:.5f}\\tLoss_G: {:.5f}\\tD(x): {:.5f}\\tD(G(z)): {:.5f}/{:.5f}'.format(epoch+1, num_epochs, disc_loss.item(), gen_loss.item(), disc_real_pred.mean().item(), disc_fake_pred.mean().item(), disc_fake_pred2.mean().item()))\n","\n","end_time = time.time()\n","print('Training process done! Time used: {} mins.'.format((end_time - start_time)/60))\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8BPp8cIIfQbI"},"source":["# Visualization"]},{"cell_type":"code","metadata":{"id":"wgHNW8IHfR6d"},"source":["plt.figure(figsize=(10,5))\n","plt.title(\"Generator and Discriminator Loss During Training\")\n","plt.plot(gen_losses,label=\"G\")\n","plt.plot(disc_losses,label=\"D\")\n","plt.xlabel(\"iterations\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CsuDe-c503DK"},"source":["fig = plt.figure()\n","plt.axis(\"off\")\n","ims = [[plt.imshow(i, animated=True)] for i in img_list]\n","ani = animation.ArtistAnimation(fig, ims, interval=500, repeat_delay=500, blit=True)\n","\n","HTML(ani.to_html5_video())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vmy4aLDW3Tmw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616295599245,"user_tz":-480,"elapsed":619,"user":{"displayName":"Yi Xuan Chan","photoUrl":"","userId":"11320233012469812964"}},"outputId":"6a5f4b6a-6eb9-465b-90bd-2446a68b93a3"},"source":["% cd /content/gdrive/MyDrive/Github"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/gdrive/MyDrive/Github\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l3i0B51FuM_G","executionInfo":{"status":"ok","timestamp":1616295648481,"user_tz":-480,"elapsed":964,"user":{"displayName":"Yi Xuan Chan","photoUrl":"","userId":"11320233012469812964"}},"outputId":"9ac1fdae-a6d7-4469-9a9d-b5468a2fa69c"},"source":["!git init dcgan"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Initialized empty Git repository in /content/gdrive/MyDrive/Github/dcgan/.git/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1fIxgaBluljd","executionInfo":{"status":"ok","timestamp":1616295697567,"user_tz":-480,"elapsed":806,"user":{"displayName":"Yi Xuan Chan","photoUrl":"","userId":"11320233012469812964"}},"outputId":"84cb9ea1-8d4c-421d-9417-d813b8fe5278"},"source":["!git status"],"execution_count":7,"outputs":[{"output_type":"stream","text":["On branch master\n","\n","No commits yet\n","\n","nothing to commit (create/copy files and use \"git add\" to track)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Kc0pVsIiuoxn"},"source":[""],"execution_count":null,"outputs":[]}]}